{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e8cad5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-13T01:03:22.936478Z",
     "iopub.status.busy": "2025-07-13T01:03:22.936274Z",
     "iopub.status.idle": "2025-07-13T01:03:33.845570Z",
     "shell.execute_reply": "2025-07-13T01:03:33.844722Z"
    },
    "papermill": {
     "duration": 10.915335,
     "end_time": "2025-07-13T01:03:33.847138",
     "exception": false,
     "start_time": "2025-07-13T01:03:22.931803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_cols = ['anger_intensity',\n",
    "'arousal_change_magnitude',\n",
    "'arousal_deviation_from_neutral',\n",
    "'arousal_onset_detected',\n",
    "'arousal_stability',\n",
    "'attention_focus_distracted',\n",
    "'attention_focus_focused',\n",
    "'attention_focus_moderate',\n",
    "'attention_stability_index',\n",
    "'avg_blink_duration_sec',\n",
    "'avg_fixation_duration_sec',\n",
    "'avg_saccade_amplitude',\n",
    "'behavioral_complexity',\n",
    "'behavioral_state_normal',\n",
    "'blink_completeness_score',\n",
    "'blink_rate_per_minute',\n",
    "'blink_rhythm_score',\n",
    "'cognitive_load_index',\n",
    "'disengagement_indicator',\n",
    "'disgust_intensity',\n",
    "'emotion_quadrant_negative_high_arousal',\n",
    "'emotion_quadrant_negative_low_arousal',\n",
    "'emotion_quadrant_neutral',\n",
    "'emotion_quadrant_positive_high_arousal',\n",
    "'emotion_transition_frequency',\n",
    "'engagement_proxy_score',\n",
    "'engagement_score',\n",
    "'engagement_state_low',\n",
    "'expression_arousal_sync',\n",
    "'expression_change_rate',\n",
    "'eye_openness_score',\n",
    "'eyebrow_furrow_intensity',\n",
    "'eyebrow_raise_intensity',\n",
    "'facial_asymmetry',\n",
    "'fixation_count_per_window',\n",
    "'frown_intensity',\n",
    "'gaze_consistency_score',\n",
    "'gaze_direction_center',\n",
    "'gaze_direction_down',\n",
    "'gaze_direction_down_left',\n",
    "'gaze_direction_down_right',\n",
    "'gaze_direction_left',\n",
    "'gaze_direction_right',\n",
    "'gaze_direction_up',\n",
    "'gaze_direction_up_left',\n",
    "'gaze_direction_up_right',\n",
    "'gaze_head_coordination',\n",
    "'head_Tx_velocity',\n",
    "'head_Ty_velocity',\n",
    "'head_Tz_velocity',\n",
    "'head_gaze_alignment_score',\n",
    "'head_movement_jerk',\n",
    "'head_movement_stability',\n",
    "'head_pitch',\n",
    "'head_pitch_acceleration',\n",
    "'head_pitch_velocity',\n",
    "'head_roll',\n",
    "'head_roll_acceleration',\n",
    "'head_roll_velocity',\n",
    "'head_tilt_direction_center',\n",
    "'head_tilt_direction_left',\n",
    "'head_yaw',\n",
    "'head_yaw_acceleration',\n",
    "'head_yaw_velocity',\n",
    "'left_eye_aperture',\n",
    "'micro_expression_frequency_per_min',\n",
    "'mouth_openness',\n",
    "'multimodal_consistency',\n",
    "'nostril_flare_intensity',\n",
    "'pupil_size_mean',\n",
    "'pupil_size_std',\n",
    "'right_eye_aperture',\n",
    "'saccade_frequency_per_sec',\n",
    "'sadness_intensity',\n",
    "'smile_intensity',\n",
    "'surprise_intensity',\n",
    "'temporal_alignment_score',\n",
    "'valence_deviation_from_neutral',\n",
    "'valence_stability']\n",
    "\n",
    "\n",
    "def apply_one_hot_encoding(df: pd.DataFrame, columns_to_encode: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies one-hot encoding to specified categorical columns in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: The input pandas DataFrame containing the features.\n",
    "        columns_to_encode: A list of column names to be one-hot encoded.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with the specified columns one-hot encoded.\n",
    "        The original categorical columns will be dropped.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter for columns that actually exist in the DataFrame\n",
    "    existing_columns_to_encode = [col for col in columns_to_encode if col in df.columns]\n",
    "    \n",
    "    if not existing_columns_to_encode:\n",
    "        print(\"No specified categorical columns found in the DataFrame to encode.\")\n",
    "        return df # Return original df if no columns exist\n",
    "        \n",
    "\n",
    "    # Use pd.get_dummies for one-hot encoding\n",
    "    # prefix ensures unique column names (e.g., 'head_tilt_direction_left')\n",
    "    # dtype=int ensures the new columns are integers (0 or 1)\n",
    "    df_encoded = pd.get_dummies(\n",
    "        df,\n",
    "        columns=existing_columns_to_encode,\n",
    "        prefix=existing_columns_to_encode,\n",
    "        dtype=int\n",
    "    )\n",
    "    \n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03fa3f82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T01:03:33.855340Z",
     "iopub.status.busy": "2025-07-13T01:03:33.854961Z",
     "iopub.status.idle": "2025-07-13T01:03:34.032949Z",
     "shell.execute_reply": "2025-07-13T01:03:34.032203Z"
    },
    "papermill": {
     "duration": 0.183741,
     "end_time": "2025-07-13T01:03:34.034381",
     "exception": false,
     "start_time": "2025-07-13T01:03:33.850640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Data Configuration - 30 second windows for production\n",
    "    SEQUENCE_LENGTH = 750  # 30 seconds at 25 FPS\n",
    "    FEATURE_DIM = 456  # Your total features\n",
    "    FRAME_RATE = 25\n",
    "    \n",
    "    # Model Architecture - Optimized for 2x16GB\n",
    "    D_MODEL = 768\n",
    "    N_HEADS = 12\n",
    "    N_ENCODER_LAYERS = 8\n",
    "    DROPOUT = 0.1\n",
    "\n",
    "    # SSL Configuration\n",
    "    SSL_TASKS = ['temporal_prediction', 'behavioral_consistency', 'attention_flow']\n",
    "    PREDICTION_HORIZON = 50  # Predict next 2 seconds\n",
    "    CONSISTENCY_WINDOW = 125  # 5 seconds for consistency check\n",
    "    \n",
    "    # Training - Full utilization of 2x16GB setup\n",
    "    BATCH_SIZE = 16  # Maximize GPU utilization\n",
    "    SSL_EPOCHS = 250  # Testing epochs\n",
    "    SSL_LR = 2e-4\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "\n",
    "\n",
    "class BehavioralDataset(Dataset):\n",
    "    \"\"\"Dataset for temporal behavioral data with SSL objectives\"\"\"\n",
    "    \n",
    "    def __init__(self, data_folder, sequence_length=750, is_train=True, max_files=None):\n",
    "        self.data_folder = Path(data_folder)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Collect all CSV files\n",
    "        self.csv_files = list(self.data_folder.glob(\"*.csv\"))\n",
    "        \n",
    "        # Limit files for testing if specified\n",
    "        if max_files:\n",
    "            self.csv_files = self.csv_files[:max_files]\n",
    "        \n",
    "        print(f\"Found {len(self.csv_files)} videos in {data_folder}\")\n",
    "        \n",
    "        # Get feature dimension from first file\n",
    "        if len(self.csv_files) > 0:\n",
    "            sample_df = pd.read_csv(self.csv_files[0])\n",
    "            self.feature_columns = final_cols\n",
    "            self.actual_feature_dim = len(final_cols)\n",
    "        else:\n",
    "            raise ValueError(\"No CSV files found in the directory\")\n",
    "    \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.csv_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            csv_path = self.csv_files[idx]\n",
    "            df = pd.read_csv(csv_path)\n",
    "            categorical_features_for_encoding = [\n",
    "                    \"head_tilt_direction\",\n",
    "                    \"emotion_quadrant\",\n",
    "                    \"engagement_state\",\n",
    "                    \"attention_focus\",\n",
    "                    \"behavioral_state\"\n",
    "                ]\n",
    "\n",
    "            df = apply_one_hot_encoding(df, categorical_features_for_encoding)\n",
    "            \n",
    "            if len(df) == 0:\n",
    "                print(f\"Warning: Empty dataframe in {csv_path}\")\n",
    "                # Return dummy data\n",
    "                features = np.zeros((self.sequence_length, self.actual_feature_dim), dtype=np.float32)\n",
    "            else:\n",
    "                # Use the pre-determined feature columns for consistency\n",
    "                for col in self.feature_columns:\n",
    "                    if col not in df.columns:\n",
    "                        df[col] = 0\n",
    "\n",
    "                feature_data = df[self.feature_columns].copy()\n",
    "                \n",
    "                # Convert all columns to numeric, forcing errors to NaN\n",
    "                for col in feature_data.columns:\n",
    "                    feature_data[col] = pd.to_numeric(feature_data[col], errors='coerce')\n",
    "\n",
    "                feature_data = feature_data.fillna(feature_data.mean()).fillna(0)\n",
    "                \n",
    "                # Handle variable length videos\n",
    "                if len(feature_data) < self.sequence_length:\n",
    "                    # Pad shorter videos by repeating last frame\n",
    "                    padding_needed = self.sequence_length - len(feature_data)\n",
    "                    if len(feature_data) > 0:\n",
    "                        last_values = feature_data.iloc[-1:].values\n",
    "                        padding = np.repeat(last_values, padding_needed, axis=0)\n",
    "                        features = np.vstack([feature_data.values, padding])\n",
    "                    else:\n",
    "                        features = np.zeros((self.sequence_length, len(feature_data.columns)), dtype=np.float32)\n",
    "                        \n",
    "                elif len(feature_data) > self.sequence_length:\n",
    "                    # For longer videos, sample random window during training\n",
    "                    if self.is_train:\n",
    "                        start_idx = np.random.randint(0, len(feature_data) - self.sequence_length + 1)\n",
    "                        features = feature_data.iloc[start_idx:start_idx + self.sequence_length].values\n",
    "                    else:\n",
    "                        # Use first window for validation\n",
    "                        features = feature_data.iloc[:self.sequence_length].values\n",
    "                else:\n",
    "                    features = feature_data.values\n",
    "                \n",
    "                # Ensure we have the right shape and type\n",
    "                features = features.astype(np.float32)\n",
    "                \n",
    "                # Handle any remaining NaN or inf values\n",
    "                features = np.nan_to_num(features, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "                \n",
    "                # Normalize features to prevent extreme values\n",
    "                features = np.clip(features, -10, 10)\n",
    "            \n",
    "            # Create SSL targets\n",
    "            ssl_targets = self._create_ssl_targets(features)\n",
    "            \n",
    "            return {\n",
    "                'features': torch.tensor(features),\n",
    "                'ssl_targets': ssl_targets,\n",
    "                'video_name': csv_path.stem\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {csv_path}: {str(e)}\")\n",
    "            dummy_features = np.zeros((self.sequence_length, self.actual_feature_dim), dtype=np.float32)\n",
    "            ssl_targets = self._create_ssl_targets(dummy_features)\n",
    "            return {\n",
    "                'features': torch.tensor(dummy_features),\n",
    "                'ssl_targets': ssl_targets,\n",
    "                'video_name': f'error_{idx}'\n",
    "            }\n",
    "    \n",
    "    def _create_ssl_targets(self, features):\n",
    "        \"\"\"Create multiple SSL objectives with fixed tensor dimensions\"\"\"\n",
    "        targets = {}\n",
    "        seq_len, feat_dim = features.shape\n",
    "        \n",
    "        # 1. Temporal Prediction: Fixed to always produce same sequence length\n",
    "        horizon = Config.PREDICTION_HORIZON\n",
    "        \n",
    "        if seq_len > horizon:\n",
    "            # Take input context from beginning, predict future frames\n",
    "            context_frames = features[:-horizon]  # Remove last 'horizon' frames\n",
    "            future_frames = features[horizon:]    # Remove first 'horizon' frames\n",
    "            \n",
    "            # Ensure both have same length (should be seq_len - horizon)\n",
    "            min_len = min(len(context_frames), len(future_frames))\n",
    "            targets['temporal_context'] = torch.tensor(context_frames[:min_len], dtype=torch.float32)\n",
    "            targets['temporal_future'] = torch.tensor(future_frames[:min_len], dtype=torch.float32)\n",
    "        else:\n",
    "            # For short sequences, predict next frame\n",
    "            targets['temporal_context'] = torch.tensor(features[:-1] if seq_len > 1 else features, dtype=torch.float32)\n",
    "            targets['temporal_future'] = torch.tensor(features[1:] if seq_len > 1 else features, dtype=torch.float32)\n",
    "        \n",
    "        # 2. Behavioral Consistency: Use different feature subsets\n",
    "        # Split features into different behavioral modalities\n",
    "        third = feat_dim // 3\n",
    "        attention_features = features[:, :third] if third > 0 else features\n",
    "        engagement_features = features[:, third:2*third] if third > 0 else features\n",
    "        emotion_features = features[:, 2*third:] if third > 0 else features\n",
    "        \n",
    "        targets['attention_trajectory'] = torch.tensor(attention_features, dtype=torch.float32)\n",
    "        targets['engagement_trajectory'] = torch.tensor(engagement_features, dtype=torch.float32)\n",
    "        targets['emotion_trajectory'] = torch.tensor(emotion_features, dtype=torch.float32)\n",
    "        \n",
    "        # 3. Cross-modal alignment\n",
    "        targets['cross_modal_pairs'] = (\n",
    "            torch.tensor(attention_features, dtype=torch.float32),\n",
    "            torch.tensor(engagement_features, dtype=torch.float32)\n",
    "        )\n",
    "        \n",
    "        return targets\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):  # Increased for longer sequences\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                           (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class BehavioralTransformer(nn.Module):\n",
    "    \"\"\"Transformer designed for behavioral temporal sequences - Full scale\"\"\"\n",
    "    \n",
    "    def __init__(self, config, actual_feature_dim):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.actual_feature_dim = actual_feature_dim\n",
    "        \n",
    "        # Input projection with layer norm\n",
    "        self.input_projection = nn.Sequential(\n",
    "            nn.Linear(actual_feature_dim, config.D_MODEL),\n",
    "            nn.LayerNorm(config.D_MODEL),\n",
    "            nn.Dropout(config.DROPOUT)\n",
    "        )\n",
    "        \n",
    "        self.pos_encoding = PositionalEncoding(config.D_MODEL, max_len=config.SEQUENCE_LENGTH)\n",
    "        \n",
    "        # Transformer encoder - Full scale\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config.D_MODEL,\n",
    "            nhead=config.N_HEADS,\n",
    "            dim_feedforward=config.D_MODEL * 4,\n",
    "            dropout=config.DROPOUT,\n",
    "            batch_first=True,\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, config.N_ENCODER_LAYERS)\n",
    "        \n",
    "        # SSL heads with better architectures\n",
    "        self.temporal_predictor = nn.Sequential(\n",
    "            nn.Linear(config.D_MODEL, config.D_MODEL),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(config.D_MODEL),\n",
    "            nn.Dropout(config.DROPOUT),\n",
    "            nn.Linear(config.D_MODEL, config.D_MODEL // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(config.D_MODEL // 2, actual_feature_dim)\n",
    "        )\n",
    "        \n",
    "        self.consistency_projector = nn.Sequential(\n",
    "            nn.Linear(config.D_MODEL, config.D_MODEL // 2),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(config.D_MODEL // 2),\n",
    "            nn.Dropout(config.DROPOUT),\n",
    "            nn.Linear(config.D_MODEL // 2, 256)  # Consistency embedding\n",
    "        )\n",
    "        \n",
    "        self.attention_flow_predictor = nn.Sequential(\n",
    "            nn.Linear(config.D_MODEL, config.D_MODEL // 2),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(config.D_MODEL // 2),\n",
    "            nn.Dropout(config.DROPOUT),\n",
    "            nn.Linear(config.D_MODEL // 2, max(actual_feature_dim // 3, 64))  # Attention flow\n",
    "        )\n",
    "        \n",
    "        # Cross-modal predictors\n",
    "        self.cross_modal_predictor = nn.Sequential(\n",
    "            nn.Linear(config.D_MODEL, config.D_MODEL // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(config.DROPOUT),\n",
    "            nn.Linear(config.D_MODEL // 2, max(actual_feature_dim // 3, 64))\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, return_embeddings=False):\n",
    "        # x shape: (batch, sequence, features)\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # Project to model dimension\n",
    "        x = self.input_projection(x)  # (batch, seq, d_model)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = x.transpose(0, 1)  # (seq, batch, d_model)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = x.transpose(0, 1)  # (batch, seq, d_model)\n",
    "        \n",
    "        # Transformer encoding\n",
    "        embeddings = self.transformer(x)  # (batch, seq, d_model)\n",
    "        \n",
    "        if return_embeddings:\n",
    "            return embeddings\n",
    "        \n",
    "        # SSL predictions\n",
    "        ssl_outputs = {}\n",
    "        \n",
    "        # Temporal prediction - predict for reduced sequence length\n",
    "        prediction_length = seq_len - Config.PREDICTION_HORIZON\n",
    "        if prediction_length > 0:\n",
    "            temporal_embeddings = embeddings[:, :prediction_length]  # Match context length\n",
    "            ssl_outputs['temporal'] = self.temporal_predictor(temporal_embeddings)\n",
    "        else:\n",
    "            # Fallback for short sequences\n",
    "            ssl_outputs['temporal'] = self.temporal_predictor(embeddings[:, :-1] if seq_len > 1 else embeddings)\n",
    "        \n",
    "        # Behavioral consistency (use mean pooling)\n",
    "        ssl_outputs['consistency'] = self.consistency_projector(embeddings.mean(dim=1))\n",
    "        \n",
    "        # Attention flow\n",
    "        ssl_outputs['attention_flow'] = self.attention_flow_predictor(embeddings)\n",
    "        \n",
    "        # Cross-modal prediction\n",
    "        ssl_outputs['cross_modal'] = self.cross_modal_predictor(embeddings)\n",
    "        \n",
    "        return ssl_outputs\n",
    "\n",
    "class BehavioralSSLLoss(nn.Module):\n",
    "    \"\"\"Multi-objective SSL loss for behavioral data with fixed tensor handling\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.cosine_loss = nn.CosineEmbeddingLoss()\n",
    "        self.huber_loss = nn.HuberLoss(delta=1.0)\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        total_loss = 0\n",
    "        loss_components = {}\n",
    "        batch_size = None\n",
    "        device = None\n",
    "        \n",
    "        # Get batch size and device from any available tensor\n",
    "        for key, value in predictions.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                batch_size = value.size(0)\n",
    "                device = value.device\n",
    "                break\n",
    "        \n",
    "        if batch_size is None or device is None:\n",
    "            # Create a default tensor on CPU if no predictions available\n",
    "            device = torch.device('cpu')\n",
    "            return torch.tensor(0.0, device=device), {}\n",
    "        \n",
    "        # 1. Temporal Prediction Loss (main objective)\n",
    "        if 'temporal_future' in targets and 'temporal' in predictions:\n",
    "            future_frames = targets['temporal_future']\n",
    "            pred_frames = predictions['temporal']\n",
    "            \n",
    "            # Ensure both tensors are on the same device\n",
    "            if future_frames.device != device:\n",
    "                future_frames = future_frames.to(device)\n",
    "            \n",
    "            # Ensure batch dimension matches\n",
    "            if future_frames.size(0) == batch_size and pred_frames.size(0) == batch_size:\n",
    "                # Match sequence lengths\n",
    "                min_seq_len = min(future_frames.size(1), pred_frames.size(1))\n",
    "                min_feat_dim = min(future_frames.size(2), pred_frames.size(2))\n",
    "                \n",
    "                if min_seq_len > 0 and min_feat_dim > 0:\n",
    "                    temporal_loss = self.huber_loss(\n",
    "                        pred_frames[:, :min_seq_len, :min_feat_dim], \n",
    "                        future_frames[:, :min_seq_len, :min_feat_dim]\n",
    "                    )\n",
    "                    loss_components['temporal'] = temporal_loss\n",
    "                    total_loss += 2.0 * temporal_loss  # Higher weight for main task\n",
    "        \n",
    "        # 2. Behavioral Consistency Loss\n",
    "        if 'attention_trajectory' in targets and 'consistency' in predictions:\n",
    "            try:\n",
    "                consistency_loss = self._compute_consistency_loss(\n",
    "                    predictions['consistency'], \n",
    "                    targets['attention_trajectory'],\n",
    "                    device\n",
    "                )\n",
    "                loss_components['consistency'] = consistency_loss\n",
    "                total_loss += 0.5 * consistency_loss\n",
    "            except Exception as e:\n",
    "                print(f\"Consistency loss error: {e}\")\n",
    "        \n",
    "        # 3. Attention Flow Smoothness Loss\n",
    "        if 'attention_flow' in predictions:\n",
    "            try:\n",
    "                flow_loss = self._compute_flow_smoothness_loss(\n",
    "                    predictions['attention_flow']\n",
    "                )\n",
    "                loss_components['flow'] = flow_loss\n",
    "                total_loss += 0.3 * flow_loss\n",
    "            except Exception as e:\n",
    "                print(f\"Flow loss error: {e}\")\n",
    "        \n",
    "        # 4. Cross-modal alignment loss\n",
    "        if 'cross_modal_pairs' in targets and 'cross_modal' in predictions:\n",
    "            try:\n",
    "                cross_modal_loss = self._compute_cross_modal_loss(\n",
    "                    predictions['cross_modal'],\n",
    "                    targets['cross_modal_pairs'],\n",
    "                    device\n",
    "                )\n",
    "                loss_components['cross_modal'] = cross_modal_loss\n",
    "                total_loss += 0.4 * cross_modal_loss\n",
    "            except Exception as e:\n",
    "                print(f\"Cross-modal loss error: {e}\")\n",
    "        \n",
    "        # Ensure we have at least some loss\n",
    "        if total_loss == 0:\n",
    "            total_loss = torch.tensor(0.001, device=device, requires_grad=True)\n",
    "        \n",
    "        return total_loss, loss_components\n",
    "    \n",
    "    def _compute_consistency_loss(self, embeddings, attention_trajectories, device):\n",
    "        \"\"\"Encourage similar attention patterns to have similar embeddings\"\"\"\n",
    "        batch_size = embeddings.size(0)\n",
    "        \n",
    "        if batch_size < 2:\n",
    "            return torch.tensor(0.0, device=device)\n",
    "        \n",
    "        # Ensure attention_trajectories is on the correct device\n",
    "        if attention_trajectories.device != device:\n",
    "            attention_trajectories = attention_trajectories.to(device)\n",
    "        \n",
    "        # Compute attention similarity matrix\n",
    "        attention_flat = attention_trajectories.view(batch_size, -1)\n",
    "        attention_sim = F.cosine_similarity(\n",
    "            attention_flat.unsqueeze(1), \n",
    "            attention_flat.unsqueeze(0), \n",
    "            dim=2\n",
    "        )\n",
    "        \n",
    "        # Compute embedding similarity matrix\n",
    "        embedding_sim = F.cosine_similarity(\n",
    "            embeddings.unsqueeze(1), \n",
    "            embeddings.unsqueeze(0), \n",
    "            dim=2\n",
    "        )\n",
    "        \n",
    "        # Loss: embedding similarity should match attention similarity\n",
    "        consistency_loss = self.mse_loss(embedding_sim, attention_sim)\n",
    "        return consistency_loss\n",
    "    \n",
    "    def _compute_flow_smoothness_loss(self, attention_flow):\n",
    "        \"\"\"Encourage smooth attention transitions\"\"\"\n",
    "        if attention_flow.size(1) <= 1:\n",
    "            return torch.tensor(0.0, device=attention_flow.device)\n",
    "            \n",
    "        # Compute temporal differences\n",
    "        flow_diff = attention_flow[:, 1:] - attention_flow[:, :-1]\n",
    "        \n",
    "        # Penalize large jumps in attention flow\n",
    "        smoothness_loss = torch.mean(torch.abs(flow_diff))\n",
    "        return smoothness_loss\n",
    "    \n",
    "    def _compute_cross_modal_loss(self, predictions, target_pairs, device):\n",
    "        \"\"\"Cross-modal alignment loss\"\"\"\n",
    "        attention_targets, engagement_targets = target_pairs\n",
    "        \n",
    "        # Ensure all tensors are on the correct device\n",
    "        if attention_targets.device != device:\n",
    "            attention_targets = attention_targets.to(device)\n",
    "        if engagement_targets.device != device:\n",
    "            engagement_targets = engagement_targets.to(device)\n",
    "        \n",
    "        # Predict engagement from attention features\n",
    "        pred_engagement = predictions\n",
    "        target_engagement = engagement_targets.mean(dim=1)  # Pool over sequence: [batch, features]\n",
    "        \n",
    "        # Pool predictions over sequence to match target dimensions\n",
    "        pred_engagement_pooled = pred_engagement.mean(dim=1)  # [batch, seq, features] -> [batch, features]\n",
    "        \n",
    "        # Match dimensions\n",
    "        min_dim = min(pred_engagement_pooled.size(-1), target_engagement.size(-1))\n",
    "        \n",
    "        if min_dim > 0:\n",
    "            cross_modal_loss = self.mse_loss(\n",
    "                pred_engagement_pooled[:, :min_dim], \n",
    "                target_engagement[:, :min_dim]\n",
    "            )\n",
    "            return cross_modal_loss\n",
    "        else:\n",
    "            # Return zero loss tensor on the correct device\n",
    "            return torch.tensor(0.0, device=device, requires_grad=True)\n",
    "\n",
    "class BehavioralSSLTrainer:\n",
    "    \"\"\"SSL Trainer for behavioral data - Full GPU utilization\"\"\"\n",
    "    \n",
    "    def __init__(self, config, actual_feature_dim):\n",
    "        self.config = config\n",
    "        self.device = config.DEVICE\n",
    "        \n",
    "        # Model\n",
    "        self.model = BehavioralTransformer(config, actual_feature_dim).to(self.device)\n",
    "        \n",
    "        # Data parallel if multiple GPUs - maximize utilization\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(f\"Using {torch.cuda.device_count()} GPUs with DataParallel\")\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "        \n",
    "        # Loss\n",
    "        self.criterion = BehavioralSSLLoss(config)\n",
    "        \n",
    "        # Optimizer - higher learning rate for larger model\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(), \n",
    "            lr=config.SSL_LR,\n",
    "            weight_decay=1e-4,\n",
    "            betas=(0.9, 0.95),  # Better for transformers\n",
    "            eps=1e-8\n",
    "        )\n",
    "        \n",
    "        # Scheduler with warmup\n",
    "        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            self.optimizer,\n",
    "            max_lr=config.SSL_LR,\n",
    "            epochs=config.SSL_EPOCHS,\n",
    "            steps_per_epoch=100,  # Approximate\n",
    "            pct_start=0.1,\n",
    "            anneal_strategy='cos'\n",
    "        )\n",
    "        \n",
    "        # Gradient scaler for mixed precision\n",
    "        self.scaler = torch.cuda.amp.GradScaler() if self.device == 'cuda' else None\n",
    "    \n",
    "    def train_epoch(self, dataloader):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        loss_components_sum = {}\n",
    "        num_batches = 0\n",
    "        \n",
    "        pbar = tqdm(dataloader, desc='Training')\n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            try:\n",
    "                features = batch['features'].to(self.device, non_blocking=True)\n",
    "                ssl_targets = batch['ssl_targets']\n",
    "                \n",
    "                # Move targets to device - Fixed to handle all tensor types properly\n",
    "                for key, value in ssl_targets.items():\n",
    "                    if isinstance(value, torch.Tensor):\n",
    "                        ssl_targets[key] = value.to(self.device, non_blocking=True)\n",
    "                    elif isinstance(value, tuple):\n",
    "                        ssl_targets[key] = tuple(\n",
    "                            v.to(self.device, non_blocking=True) if isinstance(v, torch.Tensor) else v \n",
    "                            for v in value\n",
    "                        )\n",
    "                \n",
    "                # Forward pass with mixed precision\n",
    "                if self.scaler is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        predictions = self.model(features)\n",
    "                        loss, loss_components = self.criterion(predictions, ssl_targets)\n",
    "                    \n",
    "                    # Backward pass\n",
    "                    self.optimizer.zero_grad()\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    predictions = self.model(features)\n",
    "                    loss, loss_components = self.criterion(predictions, ssl_targets)\n",
    "                    \n",
    "                    # Backward pass\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                    self.optimizer.step()\n",
    "                \n",
    "                self.scheduler.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "                \n",
    "                # Accumulate loss components\n",
    "                for key, value in loss_components.items():\n",
    "                    if key not in loss_components_sum:\n",
    "                        loss_components_sum[key] = 0\n",
    "                    loss_components_sum[key] += value.item()\n",
    "                \n",
    "                pbar.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'lr': f'{self.optimizer.param_groups[0][\"lr\"]:.2e}',\n",
    "                    'gpu_mem': f'{torch.cuda.memory_allocated()/1e9:.1f}GB' if torch.cuda.is_available() else 'N/A'\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in batch {batch_idx}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return total_loss / max(num_batches, 1), loss_components_sum\n",
    "    \n",
    "    def validate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(dataloader, desc='Validation')\n",
    "            for batch in pbar:\n",
    "                try:\n",
    "                    features = batch['features'].to(self.device, non_blocking=True)\n",
    "                    ssl_targets = batch['ssl_targets']\n",
    "                    \n",
    "                    # Move targets to device - Fixed to handle all tensor types properly\n",
    "                    for key, value in ssl_targets.items():\n",
    "                        if isinstance(value, torch.Tensor):\n",
    "                            ssl_targets[key] = value.to(self.device, non_blocking=True)\n",
    "                        elif isinstance(value, tuple):\n",
    "                            ssl_targets[key] = tuple(\n",
    "                                v.to(self.device, non_blocking=True) if isinstance(v, torch.Tensor) else v \n",
    "                                for v in value\n",
    "                            )\n",
    "                    \n",
    "                    if self.scaler is not None:\n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            predictions = self.model(features)\n",
    "                            loss, _ = self.criterion(predictions, ssl_targets)\n",
    "                    else:\n",
    "                        predictions = self.model(features)\n",
    "                        loss, _ = self.criterion(predictions, ssl_targets)\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    num_batches += 1\n",
    "                    \n",
    "                    pbar.set_postfix({\n",
    "                        'val_loss': f'{loss.item():.4f}',\n",
    "                        'gpu_mem': f'{torch.cuda.memory_allocated()/1e9:.1f}GB' if torch.cuda.is_available() else 'N/A'\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in validation batch: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        return total_loss / max(num_batches, 1)\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model\n",
    "        torch.save({\n",
    "            'model_state_dict': model_to_save.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'config': self.config,\n",
    "            'actual_feature_dim': model_to_save.actual_feature_dim\n",
    "        }, path)\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        if hasattr(self.model, 'module'):\n",
    "            self.model.module.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if 'scheduler_state_dict' in checkpoint:\n",
    "            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "def test_dataset_loading(data_path, max_files=5):\n",
    "    \"\"\"Test dataset loading with detailed diagnostics\"\"\"\n",
    "    print(f\"Testing dataset loading from: {data_path}\")\n",
    "    \n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"Path does not exist: {data_path}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        test_dataset = BehavioralDataset(data_path, sequence_length=750, is_train=True, max_files=max_files)\n",
    "        \n",
    "        if len(test_dataset) == 0:\n",
    "            print(\"No data found in dataset\")\n",
    "            return False\n",
    "        \n",
    "        # Test loading multiple samples\n",
    "        print(f\"\\nTesting {min(3, len(test_dataset))} samples:\")\n",
    "        for i in range(min(3, len(test_dataset))):\n",
    "            sample = test_dataset[i]\n",
    "            print(f\"Sample {i}:\")\n",
    "            print(f\"  Features shape: {sample['features'].shape}\")\n",
    "            print(f\"  Video name: {sample['video_name']}\")\n",
    "            print(f\"  SSL targets keys: {list(sample['ssl_targets'].keys())}\")\n",
    "            \n",
    "            # Check temporal target shapes\n",
    "            if 'temporal_future' in sample['ssl_targets']:\n",
    "                print(f\"  Temporal future shape: {sample['ssl_targets']['temporal_future'].shape}\")\n",
    "            if 'temporal_context' in sample['ssl_targets']:\n",
    "                print(f\"  Temporal context shape: {sample['ssl_targets']['temporal_context'].shape}\")\n",
    "            \n",
    "            # Check for actual data (not all zeros)\n",
    "            if torch.sum(torch.abs(sample['features'])) > 0:\n",
    "                print(f\"  ✓ Contains non-zero data\")\n",
    "            else:\n",
    "                print(f\"  ⚠ Warning: All zeros detected\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing dataset: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7316fa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T01:03:34.040948Z",
     "iopub.status.busy": "2025-07-13T01:03:34.040719Z",
     "iopub.status.idle": "2025-07-13T01:03:44.213159Z",
     "shell.execute_reply": "2025-07-13T01:03:44.212306Z"
    },
    "papermill": {
     "duration": 10.176987,
     "end_time": "2025-07-13T01:03:44.214381",
     "exception": false,
     "start_time": "2025-07-13T01:03:34.037394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /kaggle/input/ssl-base-77-features-pre-attention-finetuning/pytorch/default/1/best_behavioral_ssl_model_imni_86_feat.pth\n",
      "Using 2 GPUs with DataParallel\n",
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "def load_trainer_from_checkpoint(path):\n",
    "    \"\"\"Load BehavioralSSLTrainer from saved .pth checkpoint\"\"\"\n",
    "    print(f\"Loading model from: {path}\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(path, map_location=Config.DEVICE, weights_only = False)\n",
    "    \n",
    "    # Extract feature dim\n",
    "    actual_feature_dim = checkpoint['actual_feature_dim']\n",
    "    \n",
    "    # Instantiate trainer (this builds model, optimizer, scheduler)\n",
    "    trainer = BehavioralSSLTrainer(Config, actual_feature_dim)\n",
    "    \n",
    "    # Load model state dict\n",
    "    if hasattr(trainer.model, 'module'):\n",
    "        trainer.model.module.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        trainer.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Load optimizer and scheduler\n",
    "    trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if 'scheduler_state_dict' in checkpoint:\n",
    "        trainer.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    print(\"Model loaded successfully\")\n",
    "    return trainer\n",
    "\n",
    "model_path = \"/kaggle/input/ssl-base-77-features-pre-attention-finetuning/pytorch/default/1/best_behavioral_ssl_model_imni_86_feat.pth\"\n",
    "trainer = load_trainer_from_checkpoint(model_path)\n",
    "pretrained_ssl_model = trainer.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a83831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T01:03:44.222133Z",
     "iopub.status.busy": "2025-07-13T01:03:44.221758Z",
     "iopub.status.idle": "2025-07-13T01:03:44.414173Z",
     "shell.execute_reply": "2025-07-13T01:03:44.413381Z"
    },
    "papermill": {
     "duration": 0.198045,
     "end_time": "2025-07-13T01:03:44.415509",
     "exception": false,
     "start_time": "2025-07-13T01:03:44.217464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Use the existing Config and model definitions from the base SSL code\n",
    "class MacroAttentionConfig(Config):\n",
    "    \"\"\"Extended config for macro-attention training\"\"\"\n",
    "    \n",
    "    # Macro-attention specific settings\n",
    "    MACRO_ATTENTION_WINDOW = 30  # seconds - psychologically justified\n",
    "    MACRO_SEQUENCE_LENGTH = 750  # 30 seconds at 25 FPS\n",
    "    \n",
    "    # Attention head architecture\n",
    "    ATTENTION_HEAD_HIDDEN = 512\n",
    "    ATTENTION_HEAD_DROPOUT = 0.2\n",
    "    \n",
    "    # Training for attention head\n",
    "    ATTENTION_EPOCHS = 250\n",
    "    ATTENTION_LR = 1e-4\n",
    "    ATTENTION_BATCH_SIZE = 32\n",
    "    \n",
    "    # Paths\n",
    "    TRAIN_PATH = '/kaggle/input/daisee-feature-processed/dataset_final/Train-final'\n",
    "    TEST_PATH = '/kaggle/input/daisee-feature-processed/dataset_final/Test-final'\n",
    "    LABELS_PATH = '/kaggle/input/daisee-feature-processed/all_labels.csv'  # DAiSEE labels file\n",
    "    WEIGHTS_PATH = '/kaggle/input/ssl-base-77-features-pre-attention-finetuning/pytorch/default/1/best_behavioral_ssl_model_imni_86_feat.pth' # Pre-trained SSL weights\n",
    "\n",
    "class MacroAttentionDataset(Dataset):\n",
    "    \"\"\"Dataset for macro-attention training using 30-second windows\"\"\"\n",
    "    \n",
    "    def __init__(self, data_folder, labels_df, sequence_length=750, is_train=True):\n",
    "        self.data_folder = Path(data_folder)\n",
    "        self.labels_df = labels_df\n",
    "        self.sequence_length = sequence_length\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Load all CSV files\n",
    "        self.csv_files = list(self.data_folder.glob(\"*.csv\"))\n",
    "\n",
    "     \n",
    "        \n",
    "        # Create mapping from CSV filename to DAiSEE labels\n",
    "        self.label_mapping = self._create_label_mapping()\n",
    "        \n",
    "        # Filter files that have corresponding labels\n",
    "        self.valid_files = [f for f in self.csv_files if self._get_clip_id(f) in self.label_mapping]\n",
    "        \n",
    "        print(f\"Found {len(self.csv_files)} CSV files, {len(self.valid_files)} with labels\")\n",
    "        \n",
    "        # Get feature columns from first valid file\n",
    "        if len(self.valid_files) > 0:\n",
    "            sample_df = pd.read_csv(self.valid_files[0])\n",
    "            # Use the same final_cols as in the base model\n",
    "            self.feature_columns = final_cols\n",
    "            self.actual_feature_dim = len(final_cols)\n",
    "        else:\n",
    "            raise ValueError(\"No valid CSV files found with corresponding labels\")\n",
    "    \n",
    "    def _create_label_mapping(self):\n",
    "        \"\"\"Create mapping from ClipID to DAiSEE labels\"\"\"\n",
    "        mapping = {}\n",
    "        for _, row in self.labels_df.iterrows():\n",
    "            clip_id = row['ClipID']\n",
    "            # Convert .avi to .csv for matching\n",
    "            csv_name = str(clip_id+\".csv\")\n",
    "            mapping[csv_name] = {\n",
    "                'E': row['Engagement'],\n",
    "                'B': row['Boredom'], \n",
    "                'C': row['Confusion'],\n",
    "                'F': row['Frustration ']\n",
    "            }\n",
    "        return mapping\n",
    "    \n",
    "    def _get_clip_id(self, csv_path):\n",
    "        \"\"\"Extract clip ID from CSV filename\"\"\"\n",
    "        return csv_path.name\n",
    "    \n",
    "    def _calculate_attention_proxy_score(self, e, b, c, f):\n",
    "        \"\"\"\n",
    "        Calculate attention proxy score using psychological formula\n",
    "        Attention_Proxy_Score = (E - 0.29 * B - 0.17 * C - 0.54 * F) / 3\n",
    "        \"\"\"\n",
    "        return (e - 0.29 * b - 0.17 * c - 0.54 * f) / 3\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            csv_path = self.valid_files[idx]\n",
    "            df = pd.read_csv(csv_path)\n",
    "            \n",
    "            # Get corresponding DAiSEE labels\n",
    "            clip_id = self._get_clip_id(csv_path)\n",
    "            labels = self.label_mapping[clip_id]\n",
    "            \n",
    "            # Calculate attention proxy score\n",
    "            attention_score = self._calculate_attention_proxy_score(\n",
    "                labels['E'], labels['B'], labels['C'], labels['F']\n",
    "            )\n",
    "            \n",
    "            # Apply one-hot encoding for categorical features\n",
    "            categorical_features_for_encoding = [\n",
    "                \"head_tilt_direction\",\n",
    "                \"emotion_quadrant\", \n",
    "                \"engagement_state\",\n",
    "                \"attention_focus\",\n",
    "                \"behavioral_state\"\n",
    "            ]\n",
    "            \n",
    "            df = apply_one_hot_encoding(df, categorical_features_for_encoding)\n",
    "            \n",
    "            if len(df) == 0:\n",
    "                print(f\"Warning: Empty dataframe in {csv_path}\")\n",
    "                features = np.zeros((self.sequence_length, self.actual_feature_dim), dtype=np.float32)\n",
    "            else:\n",
    "                # Ensure all required columns exist\n",
    "                for col in self.feature_columns:\n",
    "                    if col not in df.columns:\n",
    "                        df[col] = 0\n",
    "                \n",
    "                feature_data = df[self.feature_columns].copy()\n",
    "                \n",
    "                # Convert to numeric\n",
    "                for col in feature_data.columns:\n",
    "                    feature_data[col] = pd.to_numeric(feature_data[col], errors='coerce')\n",
    "                \n",
    "                feature_data = feature_data.fillna(feature_data.mean()).fillna(0)\n",
    "                \n",
    "                # Handle variable length videos - 30-second macro-attention window\n",
    "                if len(feature_data) < self.sequence_length:\n",
    "                    # Pad shorter videos (< 30 seconds)\n",
    "                    padding_needed = self.sequence_length - len(feature_data)\n",
    "                    if len(feature_data) > 0:\n",
    "                        last_values = feature_data.iloc[-1:].values\n",
    "                        padding = np.repeat(last_values, padding_needed, axis=0)\n",
    "                        features = np.vstack([feature_data.values, padding])\n",
    "                    else:\n",
    "                        features = np.zeros((self.sequence_length, len(feature_data.columns)), dtype=np.float32)\n",
    "                        \n",
    "                elif len(feature_data) > self.sequence_length:\n",
    "                    # Clip longer videos (> 30 seconds) - take first 30 seconds\n",
    "                    features = feature_data.iloc[:self.sequence_length].values\n",
    "                else:\n",
    "                    features = feature_data.values\n",
    "                \n",
    "                # Data preprocessing\n",
    "                features = features.astype(np.float32)\n",
    "                features = np.nan_to_num(features, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "                features = np.clip(features, -10, 10)\n",
    "            \n",
    "            return {\n",
    "                'features': torch.tensor(features),\n",
    "                'attention_score': torch.tensor(attention_score, dtype=torch.float32),\n",
    "                'video_name': csv_path.stem,\n",
    "                'daisee_labels': labels\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {csv_path}: {str(e)}\")\n",
    "            dummy_features = np.zeros((self.sequence_length, self.actual_feature_dim), dtype=np.float32)\n",
    "            return {\n",
    "                'features': torch.tensor(dummy_features),\n",
    "                'attention_score': torch.tensor(0.0, dtype=torch.float32),\n",
    "                'video_name': f'error_{idx}',\n",
    "                'daisee_labels': {'E': 0, 'B': 0, 'C': 0, 'F': 0}\n",
    "            }\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    \"\"\"Shallow attention head for macro-attention regression\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim=512, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention_head = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, d_model)\n",
    "        # Global average pooling to get fixed-size representation\n",
    "        pooled = x.mean(dim=1)  # (batch_size, d_model)\n",
    "        \n",
    "        # Predict attention score\n",
    "        attention_score = self.attention_head(pooled)  # (batch_size, 1)\n",
    "        \n",
    "        return attention_score.squeeze(-1)  # (batch_size,)\n",
    "\n",
    "class MacroAttentionModel(nn.Module):\n",
    "    \"\"\"Complete model: SSL Transformer + Attention Head\"\"\"\n",
    "    \n",
    "    def __init__(self, config, actual_feature_dim, freeze_encoder=True, pretrained_ssl_model=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Use the passed model if provided\n",
    "        if pretrained_ssl_model is not None:\n",
    "            if isinstance(pretrained_ssl_model, nn.DataParallel):\n",
    "                self.ssl_transformer = pretrained_ssl_model.module\n",
    "            else:\n",
    "                self.ssl_transformer = pretrained_ssl_model\n",
    "        else:\n",
    "            self.ssl_transformer = BehavioralTransformer(config, actual_feature_dim)\n",
    "        \n",
    "        # Freeze encoder if needed\n",
    "        if freeze_encoder:\n",
    "            for param in self.ssl_transformer.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.attention_head = AttentionHead(\n",
    "            input_dim=config.D_MODEL,\n",
    "            hidden_dim=config.ATTENTION_HEAD_HIDDEN,\n",
    "            dropout=config.ATTENTION_HEAD_DROPOUT\n",
    "        )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        # Get embeddings from SSL transformer\n",
    "        embeddings = self.ssl_transformer(features, return_embeddings=True)\n",
    "        \n",
    "        # Predict attention score\n",
    "        attention_score = self.attention_head(embeddings)\n",
    "        \n",
    "        return attention_score\n",
    "\n",
    "class MacroAttentionTrainer:\n",
    "    \"\"\"Trainer for macro-attention head\"\"\"\n",
    "    \n",
    "    def __init__(self, config, actual_feature_dim, pretrained_ssl_model = pretrained_ssl_model):\n",
    "        self.config = config\n",
    "        self.device = config.DEVICE\n",
    "        \n",
    "        # Model\n",
    "        self.model = MacroAttentionModel(config, actual_feature_dim, freeze_encoder=True)\n",
    "        \n",
    "        # Load pre-trained SSL weights\n",
    "        self._load_ssl_weights()\n",
    "        \n",
    "        # Move to device and setup DataParallel\n",
    "        self.model = self.model.to(self.device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(f\"Using {torch.cuda.device_count()} GPUs with DataParallel\")\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "        \n",
    "        # Loss function for regression\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        # Optimizer - only train attention head\n",
    "        attention_params = []\n",
    "        if hasattr(self.model, 'module'):\n",
    "            attention_params = list(self.model.module.attention_head.parameters())\n",
    "        else:\n",
    "            attention_params = list(self.model.attention_head.parameters())\n",
    "            \n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            attention_params,\n",
    "            lr=config.ATTENTION_LR,\n",
    "            weight_decay=1e-4\n",
    "        )\n",
    "        \n",
    "        # Scheduler\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training history\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.best_val_loss = float('inf')\n",
    "\n",
    "\n",
    "    \n",
    "    def _load_ssl_weights(self):\n",
    "\n",
    "        try:\n",
    "            with open(self.config.WEIGHTS_PATH, 'rb') as f:\n",
    "                buffer = io.BytesIO(f.read())\n",
    "    \n",
    "            # Manually extract only the state dict\n",
    "            with zipfile.ZipFile(buffer) as archive:\n",
    "                with archive.open('archive/data.pkl') as pkl_file:\n",
    "                    state = torch.load(pkl_file, map_location=self.device, weights_only=True)\n",
    "            \n",
    "            ssl_state_dict = state['model_state_dict']\n",
    "    \n",
    "            # Filter relevant weights\n",
    "            ssl_weights = {\n",
    "                k: v for k, v in ssl_state_dict.items()\n",
    "                if not k.startswith('ssl_') and not k.startswith('temporal_') and not k.startswith('consistency_')\n",
    "            }\n",
    "    \n",
    "            self.model.ssl_transformer.load_state_dict(ssl_weights, strict=False)\n",
    "            print(\"Successfully loaded pre-trained SSL weights\")\n",
    "        except:\n",
    "            print(\"Continuing with the pretrained one...\")\n",
    "    \n",
    "    def train_epoch(self, train_loader):\n",
    "        \"\"\"Train one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        \n",
    "        # Only attention head should be trainable\n",
    "        if isinstance(self.model, nn.DataParallel):\n",
    "            self.model.module.ssl_transformer.eval()\n",
    "        else:\n",
    "            self.model.ssl_transformer.eval()\n",
    "\n",
    "        \n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc='Training Attention Head')\n",
    "        for batch in pbar:\n",
    "            features = batch['features'].to(self.device, non_blocking=True)\n",
    "            attention_scores = batch['attention_score'].to(self.device, non_blocking=True)\n",
    "            \n",
    "            # Forward pass\n",
    "            predicted_scores = self.model(features)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = self.criterion(predicted_scores, attention_scores)\n",
    "            \n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            attention_head = self.model.module.attention_head if hasattr(self.model, 'module') else self.model.attention_head\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(attention_head.parameters(), 1.0)\n",
    "\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'lr': f'{self.optimizer.param_groups[0][\"lr\"]:.2e}',\n",
    "                'gpu_mem': f'{torch.cuda.memory_allocated()/1e9:.1f}GB' if torch.cuda.is_available() else 'N/A'\n",
    "            })\n",
    "        \n",
    "        avg_loss = total_loss / max(num_batches, 1)\n",
    "        self.train_losses.append(avg_loss)\n",
    "        return avg_loss\n",
    "    \n",
    "    def validate(self, val_loader):\n",
    "        \"\"\"Validate model\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(val_loader, desc='Validation')\n",
    "            for batch in pbar:\n",
    "                features = batch['features'].to(self.device, non_blocking=True)\n",
    "                attention_scores = batch['attention_score'].to(self.device, non_blocking=True)\n",
    "                \n",
    "                # Forward pass\n",
    "                predicted_scores = self.model(features)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = self.criterion(predicted_scores, attention_scores)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "                \n",
    "                # Store predictions and targets for metrics\n",
    "                predictions.extend(predicted_scores.cpu().numpy())\n",
    "                targets.extend(attention_scores.cpu().numpy())\n",
    "                \n",
    "                pbar.set_postfix({\n",
    "                    'val_loss': f'{loss.item():.4f}',\n",
    "                    'gpu_mem': f'{torch.cuda.memory_allocated()/1e9:.1f}GB' if torch.cuda.is_available() else 'N/A'\n",
    "                })\n",
    "        \n",
    "        avg_loss = total_loss / max(num_batches, 1)\n",
    "        self.val_losses.append(avg_loss)\n",
    "        \n",
    "        return avg_loss, predictions, targets\n",
    "    \n",
    "    def train(self, train_loader, val_loader):\n",
    "        \"\"\"Complete training loop\"\"\"\n",
    "        print(\"Starting Macro-Attention Head Training...\")\n",
    "        print(f\"Training for {self.config.ATTENTION_EPOCHS} epochs\")\n",
    "        \n",
    "        for epoch in range(self.config.ATTENTION_EPOCHS):\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.config.ATTENTION_EPOCHS}\")\n",
    "            \n",
    "            # Train\n",
    "            train_loss = self.train_epoch(train_loader)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, predictions, targets = self.validate(val_loader)\n",
    "            \n",
    "            # Update scheduler\n",
    "            self.scheduler.step(val_loss)\n",
    "            \n",
    "            # Calculate validation metrics\n",
    "            mse = mean_squared_error(targets, predictions)\n",
    "            mae = mean_absolute_error(targets, predictions)\n",
    "            r2 = r2_score(targets, predictions)\n",
    "            correlation, p_value = pearsonr(targets, predictions)\n",
    "            \n",
    "            print(f\"Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"Val MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
    "            print(f\"Correlation: {correlation:.4f} (p={p_value:.4f})\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.save_model(f'best_macro_attention_model.pth')\n",
    "                print(f\"New best model saved (Val Loss: {val_loss:.4f})\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if len(self.val_losses) > 20:\n",
    "                if all(self.val_losses[-i] >= self.val_losses[-20] for i in range(1, 11)):\n",
    "                    print(\"Early stopping triggered\")\n",
    "                    break\n",
    "        \n",
    "        print(\"Training completed!\")\n",
    "        return self.train_losses, self.val_losses\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        \"\"\"Save model\"\"\"\n",
    "        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model\n",
    "        torch.save({\n",
    "            'model_state_dict': model_to_save.state_dict(),\n",
    "            'attention_head_state_dict': model_to_save.attention_head.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'config': self.config,\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses,\n",
    "            'best_val_loss': self.best_val_loss\n",
    "        }, path)\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        \"\"\"Load model\"\"\"\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        \n",
    "        if hasattr(self.model, 'module'):\n",
    "            self.model.module.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.train_losses = checkpoint.get('train_losses', [])\n",
    "        self.val_losses = checkpoint.get('val_losses', [])\n",
    "        self.best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MacroAttentionValidator:\n",
    "    \"\"\"Comprehensive validation for macro-attention model\"\"\"\n",
    "    \n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.model.eval()\n",
    "    \n",
    "    def comprehensive_evaluation(self, val_loader):\n",
    "        \"\"\"Comprehensive evaluation with multiple metrics\"\"\"\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        video_names = []\n",
    "        daisee_labels = []\n",
    "        \n",
    "        print(\"Running comprehensive evaluation...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc='Evaluating'):\n",
    "                features = batch['features'].to(self.device, non_blocking=True)\n",
    "                attention_scores = batch['attention_score'].to(self.device, non_blocking=True)\n",
    "                \n",
    "                # Forward pass\n",
    "                predicted_scores = self.model(features)\n",
    "                \n",
    "                # Store results\n",
    "                predictions.extend(predicted_scores.cpu().numpy())\n",
    "                targets.extend(attention_scores.cpu().numpy())\n",
    "                video_names.extend(batch['video_name'])\n",
    "                daisee_labels.extend(batch['daisee_labels'])\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        predictions = np.array(predictions)\n",
    "        targets = np.array(targets)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = self._calculate_metrics(predictions, targets)\n",
    "        \n",
    "        # Generate report\n",
    "        self._generate_report(predictions, targets, video_names, daisee_labels, metrics)\n",
    "        \n",
    "        return video_names, targets, predictions, metrics\n",
    "\n",
    "    \n",
    "    def _calculate_metrics(self, predictions, targets):\n",
    "        \"\"\"Calculate comprehensive metrics\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Regression metrics\n",
    "        metrics['mse'] = mean_squared_error(targets, predictions)\n",
    "        metrics['rmse'] = np.sqrt(metrics['mse'])\n",
    "        metrics['mae'] = mean_absolute_error(targets, predictions)\n",
    "        metrics['r2'] = r2_score(targets, predictions)\n",
    "        \n",
    "        # Correlation\n",
    "        correlation, p_value = pearsonr(targets, predictions)\n",
    "        metrics['correlation'] = correlation\n",
    "        metrics['correlation_p_value'] = p_value\n",
    "        \n",
    "        # Distribution statistics\n",
    "        metrics['pred_mean'] = np.mean(predictions)\n",
    "        metrics['pred_std'] = np.std(predictions)\n",
    "        metrics['target_mean'] = np.mean(targets)\n",
    "        metrics['target_std'] = np.std(targets)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _generate_report(self, predictions, targets, video_names, daisee_labels, metrics):\n",
    "        \"\"\"Generate comprehensive evaluation report\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"MACRO-ATTENTION MODEL EVALUATION REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"\\nDATASET STATISTICS:\")\n",
    "        print(f\"Number of videos: {len(predictions)}\")\n",
    "        print(f\"Prediction range: [{np.min(predictions):.4f}, {np.max(predictions):.4f}]\")\n",
    "        print(f\"Target range: [{np.min(targets):.4f}, {np.max(targets):.4f}]\")\n",
    "        \n",
    "        print(f\"\\nREGRESSION METRICS:\")\n",
    "        print(f\"Mean Squared Error (MSE): {metrics['mse']:.4f}\")\n",
    "        print(f\"Root Mean Squared Error (RMSE): {metrics['rmse']:.4f}\")\n",
    "        print(f\"Mean Absolute Error (MAE): {metrics['mae']:.4f}\")\n",
    "        print(f\"R-squared (R²): {metrics['r2']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nCORRELATION ANALYSIS:\")\n",
    "        print(f\"Pearson Correlation: {metrics['correlation']:.4f}\")\n",
    "        print(f\"P-value: {metrics['correlation_p_value']:.4f}\")\n",
    "        significance = \"Significant\" if metrics['correlation_p_value'] < 0.05 else \"Not significant\"\n",
    "        print(f\"Statistical significance: {significance}\")\n",
    "        \n",
    "        print(f\"\\nDISTRIBUTION ANALYSIS:\")\n",
    "        print(f\"Predictions - Mean: {metrics['pred_mean']:.4f}, Std: {metrics['pred_std']:.4f}\")\n",
    "        print(f\"Targets - Mean: {metrics['target_mean']:.4f}, Std: {metrics['target_std']:.4f}\")\n",
    "        \n",
    "        # Performance interpretation\n",
    "        print(f\"\\nPERFORMANCE INTERPRETATION:\")\n",
    "        if metrics['r2'] > 0.7:\n",
    "            print(\"✓ Excellent predictive performance (R² > 0.7)\")\n",
    "        elif metrics['r2'] > 0.5:\n",
    "            print(\"✓ Good predictive performance (R² > 0.5)\")\n",
    "        elif metrics['r2'] > 0.3:\n",
    "            print(\"⚠ Moderate predictive performance (R² > 0.3)\")\n",
    "        else:\n",
    "            print(\"✗ Poor predictive performance (R² < 0.3)\")\n",
    "        \n",
    "        if abs(metrics['correlation']) > 0.7:\n",
    "            print(\"✓ Strong correlation with ground truth\")\n",
    "        elif abs(metrics['correlation']) > 0.5:\n",
    "            print(\"✓ Moderate correlation with ground truth\")\n",
    "        else:\n",
    "            print(\"⚠ Weak correlation with ground truth\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    def visualize_results(self, predictions, targets, video_names, save_path=\"validation_plots.png\"):\n",
    "        \"\"\"Create visualization plots\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Scatter plot\n",
    "        axes[0, 0].scatter(targets, predictions, alpha=0.6)\n",
    "        axes[0, 0].plot([min(targets), max(targets)], [min(targets), max(targets)], 'r--', lw=2)\n",
    "        axes[0, 0].set_xlabel('Ground Truth Attention Score')\n",
    "        axes[0, 0].set_ylabel('Predicted Attention Score')\n",
    "        axes[0, 0].set_title('Predicted vs Ground Truth')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Residual plot\n",
    "        residuals = predictions - targets\n",
    "        axes[0, 1].scatter(targets, residuals, alpha=0.6)\n",
    "        axes[0, 1].axhline(y=0, color='r', linestyle='--')\n",
    "        axes[0, 1].set_xlabel('Ground Truth Attention Score')\n",
    "        axes[0, 1].set_ylabel('Residuals')\n",
    "        axes[0, 1].set_title('Residual Plot')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Distribution comparison\n",
    "        axes[1, 0].hist(targets, bins=30, alpha=0.7, label='Ground Truth', density=True)\n",
    "        axes[1, 0].hist(predictions, bins=30, alpha=0.7, label='Predictions', density=True)\n",
    "        axes[1, 0].set_xlabel('Attention Score')\n",
    "        axes[1, 0].set_ylabel('Density')\n",
    "        axes[1, 0].set_title('Distribution Comparison')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Error distribution\n",
    "        axes[1, 1].hist(residuals, bins=30, alpha=0.7, color='red')\n",
    "        axes[1, 1].set_xlabel('Residuals')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].set_title('Error Distribution')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Validation plots saved to {save_path}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "439f459c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T01:03:44.422823Z",
     "iopub.status.busy": "2025-07-13T01:03:44.422610Z",
     "iopub.status.idle": "2025-07-13T03:45:24.961113Z",
     "shell.execute_reply": "2025-07-13T03:45:24.960052Z"
    },
    "papermill": {
     "duration": 9700.543316,
     "end_time": "2025-07-13T03:45:24.962249",
     "exception": false,
     "start_time": "2025-07-13T01:03:44.418933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels...\n",
      "Loaded 8925 labels\n",
      "Label columns: ['ClipID', 'Boredom', 'Engagement', 'Confusion', 'Frustration ']\n",
      "       ClipID  Boredom  Engagement  Confusion  Frustration \n",
      "0  1100011002      0.0    0.666667        0.0           0.0\n",
      "1  1100011003      0.0    0.666667        0.0           0.0\n",
      "2  1100011004      0.0    1.000000        0.0           0.0\n",
      "3  1100011005      0.0    1.000000        0.0           0.0\n",
      "4  1100011006      0.0    1.000000        0.0           0.0\n",
      "Creating datasets...\n",
      "Found 6511 CSV files, 6511 with labels\n",
      "Found 1720 CSV files, 1577 with labels\n",
      "Actual feature dimension: 79\n",
      "Continuing with the pretrained one...\n",
      "Using 2 GPUs with DataParallel\n",
      "Starting training...\n",
      "Starting Macro-Attention Head Training...\n",
      "Training for 250 epochs\n",
      "\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [03:08<00:00,  2.16it/s, loss=0.0153, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:45<00:00,  2.17it/s, val_loss=0.0068, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0154\n",
      "Val Loss: 0.0105\n",
      "Val MSE: 0.0105, MAE: 0.0828, R²: -0.0630\n",
      "Correlation: -0.0022 (p=0.9308)\n",
      "New best model saved (Val Loss: 0.0105)\n",
      "\n",
      "Epoch 2/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:45<00:00,  2.47it/s, loss=0.0135, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:40<00:00,  2.47it/s, val_loss=0.0062, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0119\n",
      "Val Loss: 0.0104\n",
      "Val MSE: 0.0104, MAE: 0.0824, R²: -0.0536\n",
      "Correlation: 0.0934 (p=0.0002)\n",
      "New best model saved (Val Loss: 0.0104)\n",
      "\n",
      "Epoch 3/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.47it/s, loss=0.0209, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:40<00:00,  2.47it/s, val_loss=0.0069, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0118\n",
      "Val Loss: 0.0113\n",
      "Val MSE: 0.0113, MAE: 0.0865, R²: -0.1434\n",
      "Correlation: 0.1149 (p=0.0000)\n",
      "\n",
      "Epoch 4/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.48it/s, loss=0.0087, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:40<00:00,  2.47it/s, val_loss=0.0059, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0116\n",
      "Val Loss: 0.0099\n",
      "Val MSE: 0.0100, MAE: 0.0803, R²: -0.0047\n",
      "Correlation: 0.1536 (p=0.0000)\n",
      "New best model saved (Val Loss: 0.0099)\n",
      "\n",
      "Epoch 5/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.48it/s, loss=0.0201, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.49it/s, val_loss=0.0058, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0116\n",
      "Val Loss: 0.0098\n",
      "Val MSE: 0.0098, MAE: 0.0794, R²: 0.0117\n",
      "Correlation: 0.1535 (p=0.0000)\n",
      "New best model saved (Val Loss: 0.0098)\n",
      "\n",
      "Epoch 6/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.47it/s, loss=0.0058, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.53it/s, val_loss=0.0062, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0115\n",
      "Val Loss: 0.0103\n",
      "Val MSE: 0.0103, MAE: 0.0818, R²: -0.0385\n",
      "Correlation: 0.1711 (p=0.0000)\n",
      "\n",
      "Epoch 7/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:42<00:00,  2.50it/s, loss=0.0078, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.50it/s, val_loss=0.0058, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0114\n",
      "Val Loss: 0.0098\n",
      "Val MSE: 0.0098, MAE: 0.0797, R²: 0.0099\n",
      "Correlation: 0.1667 (p=0.0000)\n",
      "\n",
      "Epoch 8/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:43<00:00,  2.50it/s, loss=0.0090, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.53it/s, val_loss=0.0060, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0113\n",
      "Val Loss: 0.0099\n",
      "Val MSE: 0.0099, MAE: 0.0800, R²: 0.0027\n",
      "Correlation: 0.1769 (p=0.0000)\n",
      "\n",
      "Epoch 9/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:42<00:00,  2.50it/s, loss=0.0125, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.53it/s, val_loss=0.0059, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0113\n",
      "Val Loss: 0.0098\n",
      "Val MSE: 0.0099, MAE: 0.0800, R²: 0.0038\n",
      "Correlation: 0.1793 (p=0.0000)\n",
      "\n",
      "Epoch 10/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:45<00:00,  2.47it/s, loss=0.0246, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:38<00:00,  2.56it/s, val_loss=0.0060, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0112\n",
      "Val Loss: 0.0098\n",
      "Val MSE: 0.0098, MAE: 0.0798, R²: 0.0085\n",
      "Correlation: 0.1867 (p=0.0000)\n",
      "\n",
      "Epoch 11/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:43<00:00,  2.49it/s, loss=0.0089, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:40<00:00,  2.46it/s, val_loss=0.0057, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0112\n",
      "Val Loss: 0.0099\n",
      "Val MSE: 0.0099, MAE: 0.0801, R²: 0.0034\n",
      "Correlation: 0.1390 (p=0.0000)\n",
      "\n",
      "Epoch 12/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.47it/s, loss=0.0092, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.50it/s, val_loss=0.0056, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0113\n",
      "Val Loss: 0.0099\n",
      "Val MSE: 0.0099, MAE: 0.0801, R²: 0.0027\n",
      "Correlation: 0.1601 (p=0.0000)\n",
      "\n",
      "Epoch 13/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:42<00:00,  2.50it/s, loss=0.0074, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:40<00:00,  2.46it/s, val_loss=0.0059, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0113\n",
      "Val Loss: 0.0098\n",
      "Val MSE: 0.0098, MAE: 0.0797, R²: 0.0119\n",
      "Correlation: 0.1959 (p=0.0000)\n",
      "New best model saved (Val Loss: 0.0098)\n",
      "\n",
      "Epoch 14/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:45<00:00,  2.46it/s, loss=0.0143, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:40<00:00,  2.46it/s, val_loss=0.0062, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0112\n",
      "Val Loss: 0.0102\n",
      "Val MSE: 0.0102, MAE: 0.0814, R²: -0.0267\n",
      "Correlation: 0.1999 (p=0.0000)\n",
      "\n",
      "Epoch 15/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:46<00:00,  2.45it/s, loss=0.0167, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.50it/s, val_loss=0.0056, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0110\n",
      "Val Loss: 0.0096\n",
      "Val MSE: 0.0096, MAE: 0.0790, R²: 0.0260\n",
      "Correlation: 0.1933 (p=0.0000)\n",
      "New best model saved (Val Loss: 0.0096)\n",
      "\n",
      "Epoch 16/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:46<00:00,  2.44it/s, loss=0.0091, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:40<00:00,  2.47it/s, val_loss=0.0056, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0111\n",
      "Val Loss: 0.0097\n",
      "Val MSE: 0.0097, MAE: 0.0791, R²: 0.0239\n",
      "Correlation: 0.1924 (p=0.0000)\n",
      "\n",
      "Epoch 17/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:45<00:00,  2.47it/s, loss=0.0071, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:38<00:00,  2.55it/s, val_loss=0.0058, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0112\n",
      "Val Loss: 0.0099\n",
      "Val MSE: 0.0099, MAE: 0.0804, R²: -0.0013\n",
      "Correlation: 0.1756 (p=0.0000)\n",
      "\n",
      "Epoch 18/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.47it/s, loss=0.0061, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.53it/s, val_loss=0.0059, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0111\n",
      "Val Loss: 0.0100\n",
      "Val MSE: 0.0100, MAE: 0.0809, R²: -0.0139\n",
      "Correlation: 0.1972 (p=0.0000)\n",
      "\n",
      "Epoch 19/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.48it/s, loss=0.0058, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.50it/s, val_loss=0.0057, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0111\n",
      "Val Loss: 0.0098\n",
      "Val MSE: 0.0098, MAE: 0.0798, R²: 0.0130\n",
      "Correlation: 0.1765 (p=0.0000)\n",
      "\n",
      "Epoch 20/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:45<00:00,  2.46it/s, loss=0.0165, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.51it/s, val_loss=0.0058, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0112\n",
      "Val Loss: 0.0095\n",
      "Val MSE: 0.0095, MAE: 0.0785, R²: 0.0364\n",
      "Correlation: 0.2028 (p=0.0000)\n",
      "New best model saved (Val Loss: 0.0095)\n",
      "\n",
      "Epoch 21/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.48it/s, loss=0.0092, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.53it/s, val_loss=0.0066, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0111\n",
      "Val Loss: 0.0104\n",
      "Val MSE: 0.0105, MAE: 0.0828, R²: -0.0559\n",
      "Correlation: 0.2116 (p=0.0000)\n",
      "\n",
      "Epoch 22/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:45<00:00,  2.45it/s, loss=0.0151, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.48it/s, val_loss=0.0059, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0110\n",
      "Val Loss: 0.0098\n",
      "Val MSE: 0.0098, MAE: 0.0800, R²: 0.0095\n",
      "Correlation: 0.2126 (p=0.0000)\n",
      "\n",
      "Epoch 23/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.48it/s, loss=0.0140, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.52it/s, val_loss=0.0057, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0111\n",
      "Val Loss: 0.0102\n",
      "Val MSE: 0.0102, MAE: 0.0818, R²: -0.0305\n",
      "Correlation: 0.1360 (p=0.0000)\n",
      "\n",
      "Epoch 24/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:45<00:00,  2.46it/s, loss=0.0162, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:41<00:00,  2.41it/s, val_loss=0.0056, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0110\n",
      "Val Loss: 0.0095\n",
      "Val MSE: 0.0095, MAE: 0.0786, R²: 0.0360\n",
      "Correlation: 0.1956 (p=0.0000)\n",
      "\n",
      "Epoch 25/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.47it/s, loss=0.0120, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:40<00:00,  2.47it/s, val_loss=0.0058, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0110\n",
      "Val Loss: 0.0095\n",
      "Val MSE: 0.0095, MAE: 0.0786, R²: 0.0388\n",
      "Correlation: 0.2115 (p=0.0000)\n",
      "New best model saved (Val Loss: 0.0095)\n",
      "\n",
      "Epoch 26/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:42<00:00,  2.50it/s, loss=0.0119, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:38<00:00,  2.56it/s, val_loss=0.0059, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0110\n",
      "Val Loss: 0.0097\n",
      "Val MSE: 0.0097, MAE: 0.0794, R²: 0.0207\n",
      "Correlation: 0.2089 (p=0.0000)\n",
      "\n",
      "Epoch 27/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:45<00:00,  2.46it/s, loss=0.0123, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:40<00:00,  2.47it/s, val_loss=0.0058, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0110\n",
      "Val Loss: 0.0096\n",
      "Val MSE: 0.0096, MAE: 0.0790, R²: 0.0304\n",
      "Correlation: 0.2083 (p=0.0000)\n",
      "\n",
      "Epoch 28/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:45<00:00,  2.45it/s, loss=0.0111, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:40<00:00,  2.45it/s, val_loss=0.0058, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0109\n",
      "Val Loss: 0.0095\n",
      "Val MSE: 0.0095, MAE: 0.0785, R²: 0.0408\n",
      "Correlation: 0.2144 (p=0.0000)\n",
      "New best model saved (Val Loss: 0.0095)\n",
      "\n",
      "Epoch 29/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:47<00:00,  2.44it/s, loss=0.0091, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.53it/s, val_loss=0.0059, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0109\n",
      "Val Loss: 0.0097\n",
      "Val MSE: 0.0097, MAE: 0.0794, R²: 0.0233\n",
      "Correlation: 0.2080 (p=0.0000)\n",
      "\n",
      "Epoch 30/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:45<00:00,  2.45it/s, loss=0.0131, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.51it/s, val_loss=0.0058, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0109\n",
      "Val Loss: 0.0096\n",
      "Val MSE: 0.0096, MAE: 0.0789, R²: 0.0330\n",
      "Correlation: 0.1983 (p=0.0000)\n",
      "\n",
      "Epoch 31/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:45<00:00,  2.46it/s, loss=0.0163, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:41<00:00,  2.41it/s, val_loss=0.0060, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0109\n",
      "Val Loss: 0.0101\n",
      "Val MSE: 0.0101, MAE: 0.0813, R²: -0.0220\n",
      "Correlation: 0.2072 (p=0.0000)\n",
      "\n",
      "Epoch 32/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.47it/s, loss=0.0115, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.50it/s, val_loss=0.0058, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0109\n",
      "Val Loss: 0.0095\n",
      "Val MSE: 0.0095, MAE: 0.0788, R²: 0.0360\n",
      "Correlation: 0.2208 (p=0.0000)\n",
      "\n",
      "Epoch 33/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:43<00:00,  2.49it/s, loss=0.0086, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.49it/s, val_loss=0.0062, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0108\n",
      "Val Loss: 0.0099\n",
      "Val MSE: 0.0099, MAE: 0.0805, R²: -0.0031\n",
      "Correlation: 0.2219 (p=0.0000)\n",
      "\n",
      "Epoch 34/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.48it/s, loss=0.0108, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.49it/s, val_loss=0.0058, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0109\n",
      "Val Loss: 0.0095\n",
      "Val MSE: 0.0095, MAE: 0.0786, R²: 0.0409\n",
      "Correlation: 0.2038 (p=0.0000)\n",
      "New best model saved (Val Loss: 0.0095)\n",
      "\n",
      "Epoch 35/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:43<00:00,  2.49it/s, loss=0.0069, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.52it/s, val_loss=0.0056, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0108\n",
      "Val Loss: 0.0095\n",
      "Val MSE: 0.0095, MAE: 0.0784, R²: 0.0431\n",
      "Correlation: 0.2160 (p=0.0000)\n",
      "New best model saved (Val Loss: 0.0095)\n",
      "\n",
      "Epoch 36/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.48it/s, loss=0.0069, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.52it/s, val_loss=0.0061, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0108\n",
      "Val Loss: 0.0096\n",
      "Val MSE: 0.0097, MAE: 0.0793, R²: 0.0247\n",
      "Correlation: 0.1958 (p=0.0000)\n",
      "\n",
      "Epoch 37/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.47it/s, loss=0.0166, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.53it/s, val_loss=0.0059, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0108\n",
      "Val Loss: 0.0096\n",
      "Val MSE: 0.0096, MAE: 0.0791, R²: 0.0304\n",
      "Correlation: 0.2102 (p=0.0000)\n",
      "\n",
      "Epoch 38/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.47it/s, loss=0.0135, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:38<00:00,  2.54it/s, val_loss=0.0057, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0108\n",
      "Val Loss: 0.0096\n",
      "Val MSE: 0.0096, MAE: 0.0789, R²: 0.0332\n",
      "Correlation: 0.1895 (p=0.0000)\n",
      "\n",
      "Epoch 39/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:45<00:00,  2.46it/s, loss=0.0083, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:40<00:00,  2.46it/s, val_loss=0.0062, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0108\n",
      "Val Loss: 0.0097\n",
      "Val MSE: 0.0097, MAE: 0.0796, R²: 0.0178\n",
      "Correlation: 0.2121 (p=0.0000)\n",
      "\n",
      "Epoch 40/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:44<00:00,  2.47it/s, loss=0.0065, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.48it/s, val_loss=0.0059, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0108\n",
      "Val Loss: 0.0095\n",
      "Val MSE: 0.0095, MAE: 0.0788, R²: 0.0375\n",
      "Correlation: 0.2079 (p=0.0000)\n",
      "\n",
      "Epoch 41/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:47<00:00,  2.43it/s, loss=0.0050, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:40<00:00,  2.45it/s, val_loss=0.0063, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0108\n",
      "Val Loss: 0.0098\n",
      "Val MSE: 0.0098, MAE: 0.0800, R²: 0.0089\n",
      "Correlation: 0.1965 (p=0.0000)\n",
      "\n",
      "Epoch 42/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:48<00:00,  2.42it/s, loss=0.0200, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.48it/s, val_loss=0.0061, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0108\n",
      "Val Loss: 0.0098\n",
      "Val MSE: 0.0098, MAE: 0.0800, R²: 0.0113\n",
      "Correlation: 0.2049 (p=0.0000)\n",
      "\n",
      "Epoch 43/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:46<00:00,  2.45it/s, loss=0.0050, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.51it/s, val_loss=0.0058, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0107\n",
      "Val Loss: 0.0098\n",
      "Val MSE: 0.0098, MAE: 0.0800, R²: 0.0076\n",
      "Correlation: 0.1604 (p=0.0000)\n",
      "\n",
      "Epoch 44/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:47<00:00,  2.43it/s, loss=0.0104, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.49it/s, val_loss=0.0057, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0107\n",
      "Val Loss: 0.0097\n",
      "Val MSE: 0.0097, MAE: 0.0796, R²: 0.0168\n",
      "Correlation: 0.1926 (p=0.0000)\n",
      "\n",
      "Epoch 45/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:46<00:00,  2.45it/s, loss=0.0120, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:39<00:00,  2.49it/s, val_loss=0.0061, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0107\n",
      "Val Loss: 0.0096\n",
      "Val MSE: 0.0096, MAE: 0.0792, R²: 0.0288\n",
      "Correlation: 0.2117 (p=0.0000)\n",
      "\n",
      "Epoch 46/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:45<00:00,  2.45it/s, loss=0.0124, lr=1.00e-04, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:41<00:00,  2.40it/s, val_loss=0.0059, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0107\n",
      "Val Loss: 0.0097\n",
      "Val MSE: 0.0098, MAE: 0.0797, R²: 0.0154\n",
      "Correlation: 0.1914 (p=0.0000)\n",
      "\n",
      "Epoch 47/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Attention Head: 100%|██████████| 407/407 [02:46<00:00,  2.44it/s, loss=0.0089, lr=5.00e-05, gpu_mem=1.0GB]\n",
      "Validation: 100%|██████████| 99/99 [00:40<00:00,  2.47it/s, val_loss=0.0061, gpu_mem=1.0GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0107\n",
      "Val Loss: 0.0096\n",
      "Val MSE: 0.0096, MAE: 0.0791, R²: 0.0294\n",
      "Correlation: 0.2154 (p=0.0000)\n",
      "Early stopping triggered\n",
      "Training completed!\n",
      "\n",
      "Starting comprehensive validation...\n",
      "Running comprehensive evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 99/99 [00:39<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MACRO-ATTENTION MODEL EVALUATION REPORT\n",
      "============================================================\n",
      "\n",
      "DATASET STATISTICS:\n",
      "Number of videos: 1577\n",
      "Prediction range: [0.1297, 0.2551]\n",
      "Target range: [-0.3144, 0.3333]\n",
      "\n",
      "REGRESSION METRICS:\n",
      "Mean Squared Error (MSE): 0.0096\n",
      "Root Mean Squared Error (RMSE): 0.0981\n",
      "Mean Absolute Error (MAE): 0.0791\n",
      "R-squared (R²): 0.0294\n",
      "\n",
      "CORRELATION ANALYSIS:\n",
      "Pearson Correlation: 0.2154\n",
      "P-value: 0.0000\n",
      "Statistical significance: Significant\n",
      "\n",
      "DISTRIBUTION ANALYSIS:\n",
      "Predictions - Mean: 0.2003, Std: 0.0204\n",
      "Targets - Mean: 0.2132, Std: 0.0995\n",
      "\n",
      "PERFORMANCE INTERPRETATION:\n",
      "✗ Poor predictive performance (R² < 0.3)\n",
      "⚠ Weak correlation with ground truth\n",
      "============================================================\n",
      "\n",
      "Validation complete!\n",
      "Results saved to 'validation_results.csv'\n",
      "Final correlation: 0.2154\n",
      "Final R² score: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main training and validation pipeline\"\"\"\n",
    "import io\n",
    "import zipfile\n",
    "# Configuration\n",
    "config = MacroAttentionConfig()\n",
    "\n",
    "\n",
    "\n",
    "# Load labels\n",
    "print(\"Loading labels...\")\n",
    "labels_df = pd.read_csv(config.LABELS_PATH)\n",
    "print(f\"Loaded {len(labels_df)} labels\")\n",
    "print(f\"Label columns: {labels_df.columns.tolist()}\")\n",
    "\n",
    "# Ensure E, B, C, F are in range [0, 1] (normalize from [0, 3] if needed)\n",
    "for col in ['Engagement', 'Boredom', 'Confusion', 'Frustration ']:\n",
    "    if col in labels_df.columns:\n",
    "        labels_df[col] = labels_df[col] / 3.0  # Normalize from [0,3] to [0,1]\n",
    "\n",
    "print(labels_df.head())\n",
    "\n",
    "# Create datasets\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = MacroAttentionDataset(\n",
    "    config.TRAIN_PATH, \n",
    "    labels_df,\n",
    "    config.SEQUENCE_LENGTH\n",
    ")\n",
    "\n",
    "val_dataset = MacroAttentionDataset(\n",
    "    config.TEST_PATH,\n",
    "    labels_df,\n",
    "    config.SEQUENCE_LENGTH,\n",
    "    is_train=False\n",
    ")\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "sample_batch = next(iter(train_loader))\n",
    "actual_feature_dim = sample_batch['features'].shape[-1]\n",
    "print(f\"Actual feature dimension: {actual_feature_dim}\")\n",
    "\n",
    "attention_trainer = MacroAttentionTrainer(\n",
    "    config=config,\n",
    "    actual_feature_dim=actual_feature_dim,\n",
    "    pretrained_ssl_model=pretrained_ssl_model\n",
    ")\n",
    "\n",
    "\n",
    "# Train model\n",
    "print(\"Starting training...\")\n",
    "attention_trainer.train(train_loader, val_loader)\n",
    "\n",
    "# Save trained model\n",
    "attention_trainer.save_model('visiofocus_attention_model_final.pth')\n",
    "\n",
    "# Comprehensive validation\n",
    "print(\"\\nStarting comprehensive validation...\")\n",
    "validation_framework = MacroAttentionValidator(attention_trainer.model, config.DEVICE)\n",
    "\n",
    "\n",
    "video_names, targets, predictions, metrics = validation_framework.comprehensive_evaluation(val_loader)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'video_name': video_names,\n",
    "    'true_attention': targets,\n",
    "    'predicted_attention': predictions,\n",
    "})\n",
    "\n",
    "\n",
    "results_df.to_csv('validation_results.csv', index=False)\n",
    "\n",
    "print(\"\\nValidation complete!\")\n",
    "print(f\"Results saved to 'validation_results.csv'\")\n",
    "print(f\"Final correlation: {metrics['correlation']:.4f}\")\n",
    "print(f\"Final R² score: {metrics['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150cb14",
   "metadata": {
    "papermill": {
     "duration": 2.040285,
     "end_time": "2025-07-13T03:45:29.078918",
     "exception": false,
     "start_time": "2025-07-13T03:45:27.038633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7823495,
     "sourceId": 12452600,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 398940,
     "modelInstanceId": 378853,
     "sourceId": 469600,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9737.571053,
   "end_time": "2025-07-13T03:45:34.927186",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-13T01:03:17.356133",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
